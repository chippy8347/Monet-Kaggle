# -*- coding: utf-8 -*-

# Created by Kenny Adams, Daniel Byerly, Tyler Duong, Gavin McDuffee

"""group-8-test-kaggle-hpc-edit.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1tBY9eE7pKAzzmsT6CL6L48cBxx3YNdsM

# Introduction

### To load dataset:
- Click Add Input
- Seach "I'm Something of a Painter"
- Click first result

Import Libraries
"""

import torch
import torch.nn as nn
import torch.optim as optim
import torchvision
from torchvision import datasets, transforms
import torchvision.transforms as transforms
from torch.utils.data import DataLoader, Dataset
import torch.nn.functional as F
import matplotlib.pyplot as plt
import torch.distributed as dist
import numpy as np
import os
from PIL import Image
from itertools import cycle
from tqdm import tqdm

"""### Create Dataset Class"""

# Define paths
photo_jpg_path = "/work/classes/csc4260-001-2025s/kcadams42/photo_jpg"
monet_jpg_path = "/work/classes/csc4260-001-2025s/kcadams42/monet_jpg"

# Custom Dataset Class
# Made by Kenny Adams, modified by Tyler Duong
class CustomImageDataset(Dataset):
    def __init__(self, root_dir, transform=None):
        self.root_dir = root_dir
        self.transform = transform
        self.image_files = [f for f in os.listdir(root_dir) if f.endswith(('.jpg', '.jpeg', '.png'))]

    def __len__(self):
        return len(self.image_files)

    def __getitem__(self, idx):
        img_path = os.path.join(self.root_dir, self.image_files[idx])
        image = Image.open(img_path).convert('RGB')
        if self.transform:
            image = self.transform(image)
        return image

# Define transformations
transform = transforms.Compose([
    transforms.Resize((256, 256)),
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])
])

# Load datasets
photo_jpg_dataset = CustomImageDataset(root_dir=photo_jpg_path, transform=transform)
monet_jpg_dataset = CustomImageDataset(root_dir=monet_jpg_path, transform=transform)

# Create dataloaders
photo_jpg_loader = DataLoader(photo_jpg_dataset, batch_size=32, shuffle=True, num_workers=0, prefetch_factor=None, pin_memory=False)
monet_jpg_loader = DataLoader(monet_jpg_dataset, batch_size=16, shuffle=True, num_workers=0, prefetch_factor=None, pin_memory=False)

# Generator Model
class Generator(nn.Module):
  def __init__(self, img_channels=3, feature_maps=64):
    super(Generator, self).__init__()
    self.down1 = self.conv_block(img_channels, feature_maps, kernel_size=7, stride=1)
    self.down2 = self.conv_block(feature_maps, feature_maps * 2, kernel_size=3, stride=2)
    self.down3 = self.conv_block(feature_maps * 2, feature_maps * 4, kernel_size=3, stride=2)
    self.down4 = self.conv_block(feature_maps * 4, feature_maps * 8, kernel_size=3, stride=2)
    self.res_blocks = nn.Sequential(
        *[self.residual_block(feature_maps * 8) for _ in range(12)])
    self.up1 = self.upconv_block(feature_maps * 8, feature_maps * 4)
    self.up2 = self.upconv_block(feature_maps * 4, feature_maps * 2)
    self.up3 = self.upconv_block(feature_maps * 2, feature_maps)
    self.up4 = nn.Conv2d(feature_maps, img_channels, kernel_size=7, stride=1, padding=3)
    self.tanh = nn.Tanh()

  def conv_block(self, in_channels, out_channels, kernel_size, stride):
      return nn.Sequential(
          nn.ReflectionPad2d(1),
          nn.Conv2d(in_channels, out_channels, kernel_size, stride, padding=0),
          nn.ReLU(inplace=True),
          nn.InstanceNorm2d(out_channels)
      )

  def upconv_block(self, in_channels, out_channels):
    return nn.Sequential(
        nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True),
        nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=1, padding=1),
        nn.ReLU(inplace=True),
        nn.InstanceNorm2d(out_channels)
    )

  def residual_block(self, in_channels):
      return nn.Sequential(
          nn.Conv2d(in_channels, in_channels, kernel_size=3, stride=1, padding=1),
          nn.InstanceNorm2d(in_channels),
          nn.ReLU(inplace=True),
          nn.Conv2d(in_channels, in_channels, kernel_size=3, stride=1, padding=1),
          nn.InstanceNorm2d(in_channels),
      )

  def forward(self, x):
      x = self.down1(x)
      x = self.down2(x)
      x = self.down3(x)
      x = self.down4(x)
      x = self.res_blocks(x)
      x = self.up1(x)
      x = self.up2(x)
      x = self.up3(x)
      x = self.up4(x)
      x = self.tanh(x)
      return x

# Discriminator Model
class Discriminator(nn.Module):
    def __init__(self):
        super(Discriminator, self).__init__()
        self.down1 = self.downsample(3, 64, 4, normalize=False)
        self.down2 = self.downsample(64, 128, 4)
        self.down3 = self.downsample(128, 256, 4)
        self.zero_pad1 = nn.ZeroPad2d(1)
        self.conv = nn.Conv2d(256, 512, kernel_size=4, stride=1, padding=0, bias=False)
        self.norm1 = nn.InstanceNorm2d(512)
        self.leaky_relu = nn.LeakyReLU(0.2)
        self.dropout = nn.Dropout(0.5)
        self.zero_pad2 = nn.ZeroPad2d(1)
        self.last = nn.Conv2d(512, 1, kernel_size=4, stride=1, padding=0)

    def downsample(self, in_channels, out_channels, kernel_size, normalize=True):
        layers = [nn.Conv2d(in_channels, out_channels, kernel_size=kernel_size, stride=2, padding=1, bias=False)]
        if normalize:
            layers.append(nn.InstanceNorm2d(out_channels))
        layers.append(nn.LeakyReLU(0.2))
        return nn.Sequential(*layers)

    def forward(self, x):
        x = self.down1(x)
        x = self.down2(x)
        x = self.down3(x)
        x = self.zero_pad1(x)
        x = self.conv(x)
        x = self.norm1(x)
        x = self.leaky_relu(x)
        x = self.dropout(x)
        x = self.zero_pad2(x)
        x = self.last(x)
        return x

print("CUDA Available:", torch.cuda.is_available())
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
if device.type == "cuda":
    print("Using GPU:", torch.cuda.get_device_name(0))
else:
    print("‚ö†Ô∏è CUDA not available. Running on CPU (slower).")

generator = Generator().to(device)
discriminator = Discriminator().to(device)

g_optimizer = optim.Adam(generator.parameters(), lr=0.0001, betas=(0.5, 0.999))
d_optimizer = optim.Adam(discriminator.parameters(), lr=0.0001, betas=(0.5, 0.999))

criterion = nn.BCEWithLogitsLoss()
l1_loss = nn.L1Loss()

def tensor_to_image(tensor):
    tensor = tensor.cpu().squeeze(0)
    tensor = tensor.permute(1, 2, 0)
    image = tensor * 0.5 + 0.5
    image = image.clamp(0, 1)
    return image.numpy()

photo_cycle = cycle(photo_jpg_loader)
monet_cycle = cycle(monet_jpg_loader)

epochs = 10
log_file = open("training_losses.log", "w")
output_epoch10_folder = "/work/classes/csc4260-001-2025s/kcadams42/kaggle/10output"
os.makedirs(output_epoch10_folder, exist_ok=True)

for epoch in range(epochs):
    print(f"üîÑ Epoch {epoch + 1} started...")
    for _ in range(len(photo_jpg_loader)):
        real_photos = next(photo_cycle).to(device)
        real_monets = next(monet_cycle).to(device)
        batch_size = real_photos.size(0)

        for _ in range(5):
            g_optimizer.zero_grad()
            fake_monets = generator(real_photos)
            fake_preds = discriminator(fake_monets)
            g_loss = criterion(fake_preds, torch.ones_like(fake_preds))
            g_loss.backward()
            g_optimizer.step()
            l1 = l1_loss(fake_monets, real_photos) * 10

        d_optimizer.zero_grad()
        real_preds = discriminator(real_monets)
        real_loss = criterion(real_preds, torch.ones_like(real_preds))
        fake_preds = discriminator(fake_monets.detach())
        fake_loss = criterion(fake_preds, torch.zeros_like(fake_preds))
        d_loss = (real_loss + fake_loss) / 2
        d_loss.backward()
        d_optimizer.step()

    log_line = f"Epoch [{epoch+1}/{epochs}], G Loss: {g_loss.item():.4f}, D Loss: {d_loss.item():.4f}, L1 Loss: {l1.item():.4f}"
    print(log_line)
    log_file.write(log_line + "\n")
    log_file.flush()

    if epoch == epochs - 1:
        generator.eval()
        with torch.no_grad():
            generated = generator(real_photos[:4])
            for i, img in enumerate(generated):
                img_np = (img.cpu().numpy().transpose(1, 2, 0) * 0.5 + 0.5) * 255
                img_pil = Image.fromarray(img_np.astype("uint8"))
                img_pil.save(os.path.join(output_epoch10_folder, f"epoch10_gen_{i+1}.png"))
        generator.train()

log_file.close()

# Output Section
photo_folder = photo_jpg_path
output_folder = "/work/classes/csc4260-001-2025s/kcadams42/kaggle/output"
os.makedirs(output_folder, exist_ok=True)

generator.eval()

def preprocess_image(image_path):
    transform = transforms.Compose([
        transforms.Resize((256, 256)),
        transforms.ToTensor(),
        transforms.Normalize((0.5,), (0.5,))
    ])
    image = Image.open(image_path).convert("RGB")
    return transform(image).unsqueeze(0)

def save_image(tensor, path):
    image = tensor.squeeze(0).detach().cpu().numpy()
    image = (image * 0.5 + 0.5) * 255
    image = Image.fromarray(image.astype("uint8").transpose(1, 2, 0))
    image.save(path)

for image_name in tqdm(os.listdir(photo_folder)):
    image_path = os.path.join(photo_folder, image_name)
    output_path = os.path.join(output_folder, image_name)

    with torch.no_grad():
        input_image = preprocess_image(image_path).to(device)
        generated_monet = generator(input_image)
        save_image(generated_monet, output_path)

print(f"Conversion complete. Monet-style images saved in {output_folder}")
